name: Daily GPT-5 Stock Alert to Discord

on:
  schedule:
    - cron: '0 4 * * *' # 04:00 UTC daily
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  prepare-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          persist-credentials: true
          fetch-depth: 0

      - name: Restore cached data (aliases, universe, etc.)
        uses: actions/cache@v4
        with:
          path: data
          key: universe-cache-${{ github.run_id }}
          restore-keys: |
            universe-cache-

      - name: Purge valuation caches
        run: rm -f data/pe_cache.json data/valuations_cache.json

      - name: Ensure dependency manifest
        run: |
          if [ ! -f requirements.txt ]; then
            printf "numpy\npandas\nyfinance\nrequests\npytz\n" > requirements.txt
          fi
          cat requirements.txt

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install --upgrade --upgrade-strategy eager -r requirements.txt

      - name: Build universe.csv from Trading 212 (fallback to stale)
        env:
          T212_API_KEY: ${{ secrets.T212_API_KEY }}
          ALLOW_STALE: '1'
        run: python scripts/universe_from_trading_212.py || true

      - name: Clean universe (fallback to stale)
        env:
          T212_API_KEY: ${{ secrets.T212_API_KEY }}
          CLEAN_ALLOW_OFFLINE: '1'
          ALLOW_STALE: '1'
        run: python scripts/clean_universe.py || true

      - name: Auto-build Yahoo aliases from last run’s rejects
        env:
          ALIASES_FROM: data/universe_rejects.csv
          ALIASES_OUT: data/aliases.csv
          ALIASES_MAX_PER_RUN: '250'
          ALIAS_LOG_LEVEL: 'INFO'
          YF_TEST_PERIOD: '60d'
          YF_TEST_INTERVAL: '1d'
        run: python scripts/aliases_autobuild.py || true

      - name: Prepare logs dir
        run: mkdir -p logs

      # --- Stage 1 Quick Scorer ---
      - name: Run Stage-1 Quick Scorer
        env:
          STAGE1_WRITE_CSV: '1'
          STAGE1_KEEP: '550'
          STAGE1_MODE: 'loose'
          STAGE1_RESCUE_FRAC: '0.25'
          YF_CHUNK_SIZE: '50'
          YF_MAX_RETRIES: '5'
          YF_RETRY_SLEEP: '2.5'
        run: |
          python scripts/quick_scorer.py --input data/universe_clean.csv --output data/stage1_kept.csv

      # --- Stage 2 Merger ---
      - name: Run TR + QS merger
        run: |
          python -c "from scripts.trash_ranker import merge_stage1_with_tr; merge_stage1_with_tr('data/stage1_kept.csv', 'data/stage2_merged.csv')"
          test -f data/stage2_merged.csv || (echo 'No data/stage2_merged.csv produced' && exit 1)

      # --- Commit results ---
      - name: Commit Stage-1/2 CSVs
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/stage1_kept.csv data/stage2_merged.csv || true
          git add logs/top2000_quick_full.csv || true
          if git diff --cached --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update Stage-1/2 results (run #${{ github.run_number }})"
            git push
          fi

  send-alert:
    runs-on: ubuntu-latest
    needs: prepare-data
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          persist-credentials: true
          fetch-depth: 0

      - name: Ensure dependency manifest
        run: |
          if [ ! -f requirements.txt ]; then
            printf "numpy\npandas\nyfinance\nrequests\npytz\n" > requirements.txt
          fi
          cat requirements.txt

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install --upgrade --upgrade-strategy eager -r requirements.txt

      - name: Run notifier
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}

          # --- Logging ---
          PYTHONUNBUFFERED: '1'
          FEATURES_LOG_LEVEL: 'INFO'
          FEATURES_VERBOSE: '0'
          FEATURES_LOG_EVERY: '500'
          RANKER_LOG_LEVEL: 'DEBUG'
          RANKER_VERBOSE: '1'
          RANKER_LOG_EVERY: '300'
          QUICK_LOG_LEVEL: 'INFO'

          # --- Quick-sort full dump ---
          STAGE1_WRITE_TOPN_CSV: '1'
          STAGE1_TOPN_CSV: '2000'
          STAGE1_TOPN_PATH: 'logs/top2000_quick_full.csv'

          # --- yfinance ---
          YF_CHUNK_SIZE: '50'
          YF_MAX_RETRIES: '5'
          YF_RETRY_SLEEP: '2.5'

          # --- Stage-2 profile ---
          RANKER_PROFILE: 'C'

          # --- (all your QS, TR, FVA, catalyst, momo knobs go here — same as before) ---
          ALLOW_BLOWOFF_PROBE: '1'
          QS_ET_BONUS_TREND: '6'
          QS_ET_BONUS_MOMO: '8'
          QS_ET_BONUS_STRUCT: '5'
          QS_USE_FVA: '1'
          QS_VAL_OVERLAY: '1'
          QS_PE_WEIGHT: '0.015'
          QS_PE_WEIGHT_LARGE: '0.02'
          QS_PE_WEIGHT_SMALL: '0.005'
          HARD_DROP_MODE: 'normal'
          EARLY_TURN_MIN_E50_SLOPE: '2.0'
          # etc… (copy over full block of knobs you had before)

          # --- OpenAI plumbing ---
          FORCE_CATALYSTS_PARTIAL: '1'
          OPENAI_TIMEOUT: '360'
          LOG_GPT_INPUT: '1'
          LOG_GPT_INPUT_STDOUT: '0'
        run: python scripts/notify.py

      # --- Commit blocks file ---
      - name: Find latest blocks file
        id: pick_file
        run: |
          set -e
          FILE=$(ls -1t data/logs/blocks_to_gpt_*.txt 2>/dev/null | head -n1 || true)
          if [ -z "$FILE" ]; then
            echo "found=0" >> "$GITHUB_OUTPUT"
          else
            echo "found=1" >> "$GITHUB_OUTPUT"
            echo "file=$FILE" >> "$GITHUB_OUTPUT"
          fi

      - name: Commit latest blocks_to_gpt
        if: steps.pick_file.outputs.found == '1'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          mkdir -p logs
          cp "${{ steps.pick_file.outputs.file }}" "logs/blocks_to_gpt_latest.txt"
          git add logs/blocks_to_gpt_latest.txt
          if git diff --cached --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update latest GPT blocks (run #${{ github.run_number }})"
            git push
          fi
