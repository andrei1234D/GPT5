name: Daily GPT-5 Stock Alert to Discord

on:
  schedule:
    - cron: '0 4 * * *' # Runs every day at 04:00 UTC.
  workflow_dispatch: # Allows manual runs from the Actions tab.

permissions:
  contents: write

jobs:
  send-alert:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          persist-credentials: true
          fetch-depth: 0

      - name: Restore cached data (aliases, universe, etc.)
        uses: actions/cache@v4
        with:
          path: data
          key: universe-cache-${{ github.run_id }}
          restore-keys: |
            universe-cache-

      - name: Purge valuation caches
        run: |
          rm -f data/pe_cache.json data/valuations_cache.json

      - name: Ensure dependency manifest
        run: |
          if [ ! -f requirements.txt ]; then
            printf "numpy\npandas\nyfinance\nrequests\npytz\n" > requirements.txt
          fi
          cat requirements.txt

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip install --upgrade --upgrade-strategy eager numpy pandas yfinance requests pytz

      - name: Verify environment (debug)
        run: |
          python -V
          python -c "import pandas as pd, yfinance as yf, numpy as np; print('pandas', pd.__version__, 'yfinance', yf.__version__, 'numpy', np.__version__)"

      - name: Build universe.csv from Trading 212 (fallback to stale)
        env:
          T212_API_KEY: ${{ secrets.T212_API_KEY }}
          ALLOW_STALE: '1'
        run: |
          python scripts/universe_from_trading_212.py || true
          ls -lah data || true
          ls -lah data/universe.csv || true

      - name: Clean universe (fallback to stale)
        env:
          T212_API_KEY: ${{ secrets.T212_API_KEY }}
          CLEAN_ALLOW_OFFLINE: '1'
          ALLOW_STALE: '1'
        run: |
          python scripts/clean_universe.py || true
          wc -l data/universe_clean.csv || true
          head -n 5 data/universe_clean.csv || true

      - name: Auto-build Yahoo aliases from last run’s rejects
        env:
          ALIASES_FROM: data/universe_rejects.csv
          ALIASES_OUT: data/aliases.csv
          ALIASES_MAX_PER_RUN: '250'
          ALIAS_LOG_LEVEL: 'INFO'
          YF_TEST_PERIOD: '60d'
          YF_TEST_INTERVAL: '1d'
        run: |
          python scripts/aliases_autobuild.py || true

      - name: Prepare logs dir (for Stage-1 TopN CSV)
        run: mkdir -p logs

      - name: Run notifier
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}

          # --- Logging ---
          PYTHONUNBUFFERED: '1'
          FEATURES_LOG_LEVEL: 'INFO'
          FEATURES_VERBOSE: '0'
          FEATURES_LOG_EVERY: '500'
          RANKER_LOG_LEVEL: 'DEBUG'
          RANKER_VERBOSE: '1'
          RANKER_LOG_EVERY: '300'
          QUICK_LOG_LEVEL: 'INFO'

          # --- Quick-sort full dump (top 2000) ---
          STAGE1_WRITE_TOPN_CSV: '1'
          STAGE1_TOPN_CSV: '2000'
          STAGE1_TOPN_PATH: 'logs/top2000_quick_full.csv'

          # --- yfinance ---
          YF_CHUNK_SIZE: '50'
          YF_MAX_RETRIES: '5'
          YF_RETRY_SLEEP: '2.5'

          # --- Tiering ---
          TIER_POLICY: 'TOPK_ADV'
          TIER_TOPK_LARGE: '500'
          TIER_BACKFILL_UNKNOWN_AS: 'small'

          # --- Stage-1 quick pass (looser to surface more buys) ---
          STAGE1_MODE: 'loose' # <- was normal
          STAGE1_KEEP: '350' # <- was 300
          STAGE1_MIN_SMALL: '130'
          STAGE1_MIN_LARGE: '130'
          STAGE1_RESCUE_FRAC: '0.25' # <- was 0.15
          QS_USE_XS: '1'

          # --- Stage-2 profile (more aggressive) ---
          RANKER_PROFILE: 'A' # <- was B

          # --- Early-turn tiny boosts (OK to leave) ---
          QS_ET_BONUS_TREND: '6'
          QS_ET_BONUS_MOMO: '8'
          QS_ET_BONUS_STRUCT: '5'

          # --- FVA KO tuning (require more extension before KO) ---
          # Tier-aware (quick_scorer uses *_SMALL/LARGE if present)
          QS_FVA_KO_PCT_SMALL: '50' # <- was 45
          QS_FVA_KO_PCT_LARGE: '35' # <- was 28

          # --- Hard filters (looser) ---
          HARD_DROP_MODE: 'loose' # <- was normal
          HARD_GRACE_ATR: '3.0' # <- was 2.0
          HARD_EMA_ROLLOVER: '0' # allow early-turns through
          TR_EARN_BLACKOUT_DAYS: '0'

          # --- Early-turn detector (unchanged; good) ---
          EARLY_TURN_MIN_E50_SLOPE: '2.0'
          EARLY_TURN_RSI_LO: '47.0'
          EARLY_TURN_RSI_HI: '63.0'
          EARLY_TURN_VS200_LO: '-12.0'
          EARLY_TURN_VS200_HI: '8.0'
          EARLY_TURN_VOL_LO: '110.0'
          EARLY_TURN_VOL_HI: '220.0'
          EARLY_TURN_VS200_PAD: '5.0'

          # --- Lead/anticipation setup (a bit wider, higher cap) ---
          QS_SETUP_ATR_MAX: '6.5' # <- was 6.0
          QS_SETUP_VS50_MIN: '-5' # <- was -4
          QS_SETUP_VS50_MAX: '12' # <- was 10
          QS_SETUP_VS200_MIN: '-3' # <- was -2
          QS_SETUP_VOL_ABS_MAX: '70' # <- was 60
          QS_SETUP_RSI_LO: '45'
          QS_SETUP_RSI_HI: '64' # <- was 62
          QS_SETUP_E50S_MIN: '0.5'
          QS_SETUP_E50S_MAX: '9' # <- was 8
          QS_SETUP_CAP_SMALL: '14' # <- was 12
          QS_SETUP_CAP_LARGE: '16' # <- was 14

          # --- Momentum “chase” penalty (lighter) ---
          QS_MOMO_CHASE_KNEE: '40' # <- was 35
          QS_MOMO_CHASE_SLOPE: '0.45' # <- was 0.6
          QS_MOMO_CHASE_PEN_MAX: '8' # <- was 15

          # --- Momo chase (trash_ranker) ---
          TR_CHASE_KNEE: '40' # <- was 35
          TR_CHASE_SLOPE: '0.004' # <- was 0.006
          TR_CHASE_MAX: '0.12' # <- was 0.18 (cap is fraction)

          # --- Quick scorer weights (more structure, less risk headwind) ---
          QS_W_TREND_SMALL: '0.26'
          QS_W_MOMO_SMALL: '0.20'
          QS_W_STRUCT_SMALL: '0.40'
          QS_W_RISK_SMALL: '0.14'
          QS_W_TREND_LARGE: '0.30'
          QS_W_MOMO_LARGE: '0.20'
          QS_W_STRUCT_LARGE: '0.40'
          QS_W_RISK_LARGE: '0.10'

          # --- P/E tilt (keep tiny to avoid suppressing growth) ---
          QS_PE_WEIGHT: '0.015' # <- was 0.02
          QS_PE_WEIGHT_LARGE: '0.02' # <- was 0.03
          QS_PE_WEIGHT_SMALL: '0.005' # <- was 0.01

          # --- FVA & AVWAP shaping (ease penalties, keep rewards) ---
          QS_USE_FVA: '1'
          QS_FVA_PEN_MAX_SMALL: '12' # <- was 14
          QS_FVA_PEN_MAX_LARGE: '20' # <- was 30
          QS_FVA_BONUS_MAX_SMALL: '8' # <- was 6
          QS_FVA_BONUS_MAX_LARGE: '8' # <- was 6
          QS_STRUCT_PREM_CAP: '0' # keep neutral

          # --- Valuation overlay into structure (slightly higher cap) ---
          QS_VAL_OVERLAY: '1'
          QS_VAL_OVERLAY_MAX: '20' # <- was 16

          # ---- Blowoff probe controls (easier but still sane) ----
          ALLOW_BLOWOFF_PROBE: '1'
          PROBE_MIN_EV: '2.2' # sweet spot; 1.8 was very loose
          PROBE_MAX_VOL_SPIKE: '200' # block true blow-offs

          # Overheat gates (easier than 78/83/87; include vs50 gates)
          OVERHEAT_A_RSI: '76'
          OVERHEAT_B_RSI: '82'
          OVERHEAT_C_RSI: '86'
          OVERHEAT_A_VS50: '18'
          OVERHEAT_B_VS50: '32'
          OVERHEAT_C_VS50: '45'

          # Probe rebate (small but helpful)
          PROBE_ADD_BACK_A: '6' # <- was 5
          PROBE_ADD_BACK_B: '9' # <- was 8
          PROBE_ADD_BACK_C: '12'
          PROBE_STRUCT_SHARE: '0.50'

          # Momentum-carry discount on FVA KO penalty (more forgiving)
          KO_MOMO_DISCOUNT: '0.35' # <- was 0.40
          KO_MOMO_DISCOUNT_STRONG: '0.25' # <- was 0.30

          # --- ATH guard (lighter trigger & haircut) ---
          ATH_GUARD: '1'
          ATH_NEAR_PCT: '0.8' # fewer names flagged as "near ATH"
          ATH_MIN_RSI: '82' # stronger condition to trigger
          ATH_MIN_VS50: '28'
          ATH_VOL_RELIEF: '40' # relief kicks in more often
          ATH_SCORE_HAIRCUT: '16' # smaller haircut

          # --- Prompt plumbing ---
          FORCE_CATALYSTS_PARTIAL: '1'

          # --- OpenAI call timeout ---
          OPENAI_TIMEOUT: '360'

          # --- Dump exact GPT inputs ---
          LOG_GPT_INPUT: '1'
          LOG_GPT_INPUT_STDOUT: '0'
        run: |
          python scripts/notify.py

      - name: Find latest blocks file
        id: pick_file
        shell: bash
        run: |
          set -e
          FILE=$(ls -1t data/logs/blocks_to_gpt_*.txt 2>/dev/null | head -n1 || true)
          if [ -z "$FILE" ]; then
            echo "found=0" >> "$GITHUB_OUTPUT"
            echo "No blocks_to_gpt_*.txt found"
          else
            echo "found=1" >> "$GITHUB_OUTPUT"
            echo "file=$FILE" >> "$GITHUB_OUTPUT"
            echo "basename=$(basename "$FILE")" >> "$GITHUB_OUTPUT"
          fi

      - name: Commit blocks file to repo (overwrite single file)
        if: steps.pick_file.outputs.found == '1'
        shell: bash
        run: |
          set -e
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          mkdir -p logs
          cp "${{ steps.pick_file.outputs.file }}" "logs/blocks_to_gpt_latest.txt"
          git add "logs/blocks_to_gpt_latest.txt"
          if git diff --cached --quiet; then
            echo "No changes to commit."
          else
            git commit -m "Update latest GPT blocks (run #${{ github.run_number }})"
            git push
          fi

      - name: Commit top2000 quick-sort CSV to repo
        shell: bash
        run: |
          set -e
          FILE="logs/top2000_quick_full.csv"
          if [ -f "$FILE" ]; then
            git config user.name  "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git add "$FILE"
            if git diff --cached --quiet; then
              echo "No changes to commit for $FILE."
            else
              git commit -m "Add/update top2000 quick-sort CSV (run #${{ github.run_number }})"
              git push
            fi
          else
            echo "No $FILE produced."
          fi

      - name: Commit top200 kept CSV to repo
        shell: bash
        run: |
          set -e
          FILE="data/stage1_kept.csv"
          if [ -f "$FILE" ]; then
            git config user.name  "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git add "$FILE"
            if git diff --cached --quiet; then
              echo "No changes to commit for $FILE."
            else
              git commit -m "Add/update top200 kept CSV (run #${{ github.run_number }})"
              git push
            fi
          else
            echo "No $FILE produced (enable STAGE1_WRITE_CSV=1)."
          fi
